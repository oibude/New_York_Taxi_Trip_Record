{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, row_number, monotonically_increasing_id\n",
    "from pyspark.sql.window import Window\n",
    "import psycopg2 as psy\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the PostgreSQL JDBC driver\n",
    "jdbc_driver_path= r'C:\\Users\\HP SPECTRE\\Documents\\Data Journey\\10Alytics\\ETL_Orchestration\\class_case_study\\New_York_Taxi_Trip_Record\\postgresql-42.7.3.jar'\n",
    "\n",
    "#Setup Spark Session\n",
    "spark= SparkSession.builder.appName('NY Trip Data') \\\n",
    "                   .config(\"spark.jars\" , jdbc_driver_path) \\\n",
    "                   .config (\"spark.executor.memory\", \"4g\") \\\n",
    "                   .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= r\"C:\\Users\\HP SPECTRE\\Documents\\Data Journey\\10Alytics\\ETL_Orchestration\\class_case_study\\yellow_tripdata_2009-01DATASET.parquet\"\n",
    "ny_df=spark.read.option('mode','DROPMALFORMED' ).parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset is: 14092413\n"
     ]
    }
   ],
   "source": [
    "print('Length of dataset is:', ny_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+---------+-----------------+------------------+---------+------------+-----------------+---------+-------+-------+---------+---------+\n",
      "|vendor_name|Trip_Pickup_DateTime|Trip_Dropoff_DateTime|Passenger_Count|     Trip_Distance|         Start_Lon|Start_Lat|Rate_Code|store_and_forward|           End_Lon|  End_Lat|Payment_Type|         Fare_Amt|surcharge|mta_tax|Tip_Amt|Tolls_Amt|Total_Amt|\n",
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+---------+-----------------+------------------+---------+------------+-----------------+---------+-------+-------+---------+---------+\n",
      "|        VTS| 2009-01-04 02:52:00|  2009-01-04 03:02:00|              1|              2.63|        -73.991957|40.721567|     NULL|             NULL|        -73.993803|40.695922|        CASH|              8.9|      0.5|   NULL|    0.0|      0.0|      9.4|\n",
      "|        VTS| 2009-01-04 03:31:00|  2009-01-04 03:38:00|              3|              4.55|        -73.982102| 40.73629|     NULL|             NULL|         -73.95585| 40.76803|      Credit|             12.1|      0.5|   NULL|    2.0|      0.0|     14.6|\n",
      "|        VTS| 2009-01-03 15:43:00|  2009-01-03 15:57:00|              5|             10.35|        -74.002587|40.739748|     NULL|             NULL|        -73.869983|40.770225|      Credit|             23.7|      0.0|   NULL|   4.74|      0.0|    28.44|\n",
      "|        DDS| 2009-01-01 20:52:58|  2009-01-01 21:14:00|              1|               5.0|        -73.974267|40.790955|     NULL|             NULL|-73.99655799999998|40.731849|      CREDIT|             14.9|      0.5|   NULL|   3.05|      0.0|    18.45|\n",
      "|        DDS| 2009-01-24 16:18:23|  2009-01-24 16:24:56|              1|               0.4|         -74.00158|40.719382|     NULL|             NULL|-74.00837799999998| 40.72035|        CASH|              3.7|      0.0|   NULL|    0.0|      0.0|      3.7|\n",
      "|        DDS| 2009-01-16 22:35:59|  2009-01-16 22:43:35|              2|               1.2|        -73.989806|40.735006|     NULL|             NULL|        -73.985021|40.724494|        CASH|              6.1|      0.5|   NULL|    0.0|      0.0|      6.6|\n",
      "|        DDS| 2009-01-21 08:55:57|  2009-01-21 09:05:42|              1|               0.4|-73.98404999999998|40.743544|     NULL|             NULL|         -73.98026|40.748926|      CREDIT|              5.7|      0.0|   NULL|    1.0|      0.0|      6.7|\n",
      "|        VTS| 2009-01-04 04:31:00|  2009-01-04 04:36:00|              1|              1.72|        -73.992635|40.748362|     NULL|             NULL|        -73.995585|40.728307|        CASH|              6.1|      0.5|   NULL|    0.0|      0.0|      6.6|\n",
      "|        CMT| 2009-01-05 16:29:02|  2009-01-05 16:40:21|              1|               1.6|         -73.96969|40.749244|     NULL|             NULL|        -73.990413|40.751082|      Credit|8.699999999999998|      0.0|   NULL|    1.3|      0.0|     10.0|\n",
      "|        CMT| 2009-01-05 18:53:13|  2009-01-05 18:57:45|              1|0.6999999999999998|        -73.955173|40.783044|     NULL|             NULL|-73.95859799999998|40.774822|        Cash|              5.9|      0.0|   NULL|    0.0|      0.0|      5.9|\n",
      "|        CMT| 2009-01-05 08:15:38|  2009-01-05 08:16:44|              1|0.2999999999999999|        -73.986824|40.750893|     NULL|             NULL|-73.98411799999998|40.751437|        Cash|              2.9|      0.0|   NULL|    0.0|      0.0|      2.9|\n",
      "|        CMT| 2009-01-05 06:21:43|  2009-01-05 06:28:41|              1|               2.3|          -74.0061|40.748432|     NULL|             NULL|        -73.978437|40.762481|        Cash|              7.7|      0.0|   NULL|    0.0|      0.0|      7.7|\n",
      "|        DDS| 2009-01-20 13:44:02|  2009-01-20 13:52:43|              2|               2.1|        -73.983339|40.744782|     NULL|             NULL|         -73.98116|40.720835|        CASH|              7.3|      0.0|   NULL|    0.0|      0.0|      7.3|\n",
      "|        CMT| 2009-01-05 16:19:53|  2009-01-05 16:26:48|              2|               1.2|         -73.97351| 40.76028|     NULL|             NULL|        -73.962933|40.775119|        Cash|              6.7|      0.0|   NULL|    0.0|      0.0|      6.7|\n",
      "|        CMT| 2009-01-05 17:22:16|  2009-01-05 17:27:25|              1|               0.8|        -73.984426| 40.75748|     NULL|             NULL|-73.98251899999998|40.767165|        Cash|              5.9|      0.0|   NULL|    0.0|      0.0|      5.9|\n",
      "|        CMT| 2009-01-05 16:02:52|  2009-01-05 16:18:43|              1|               4.5|-73.99106399999998|40.727654|     NULL|             NULL|-73.94577099999998| 40.77765|        Cash|             13.9|      0.0|   NULL|    0.0|      0.0|     13.9|\n",
      "|        CMT| 2009-01-05 12:15:06|  2009-01-05 12:27:58|              1|               1.7|        -74.001678|  40.7473|     NULL|             NULL|-73.97895699999998|40.750394|        Cash|              8.5|      0.0|   NULL|    0.0|      0.0|      8.5|\n",
      "|        CMT| 2009-01-05 07:49:57|  2009-01-05 07:54:11|              1|               1.0|-73.98245699999998|40.731475|     NULL|             NULL|        -73.973011|40.743387|      Credit|              4.5|      0.0|   NULL|    1.0|      0.0|      5.5|\n",
      "|        DDS| 2009-01-23 23:57:34|  2009-01-24 00:12:40|              2|               5.0|        -73.992554|40.724476|     NULL|             NULL|-73.95306499999998|40.777555|      CREDIT|             13.3|      0.5|   NULL|   3.45|      0.0|    17.25|\n",
      "|        CMT| 2009-01-05 10:23:13|  2009-01-05 10:33:56|              1|               1.3|        -73.990089|40.759027|     NULL|             NULL|        -73.983974|40.746938|        Cash|              7.3|      0.0|   NULL|    0.0|      0.0|      7.3|\n",
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+---------+-----------------+------------------+---------+------------+-----------------+---------+-------+-------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vendor_name',\n",
       " 'Trip_Pickup_DateTime',\n",
       " 'Trip_Dropoff_DateTime',\n",
       " 'Passenger_Count',\n",
       " 'Trip_Distance',\n",
       " 'Start_Lon',\n",
       " 'Start_Lat',\n",
       " 'Rate_Code',\n",
       " 'store_and_forward',\n",
       " 'End_Lon',\n",
       " 'End_Lat',\n",
       " 'Payment_Type',\n",
       " 'Fare_Amt',\n",
       " 'surcharge',\n",
       " 'mta_tax',\n",
       " 'Tip_Amt',\n",
       " 'Tolls_Amt',\n",
       " 'Total_Amt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking columns\n",
    "ny_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendor_name: string (nullable = true)\n",
      " |-- Trip_Pickup_DateTime: string (nullable = true)\n",
      " |-- Trip_Dropoff_DateTime: string (nullable = true)\n",
      " |-- Passenger_Count: long (nullable = true)\n",
      " |-- Trip_Distance: double (nullable = true)\n",
      " |-- Start_Lon: double (nullable = true)\n",
      " |-- Start_Lat: double (nullable = true)\n",
      " |-- Rate_Code: double (nullable = true)\n",
      " |-- store_and_forward: double (nullable = true)\n",
      " |-- End_Lon: double (nullable = true)\n",
      " |-- End_Lat: double (nullable = true)\n",
      " |-- Payment_Type: string (nullable = true)\n",
      " |-- Fare_Amt: double (nullable = true)\n",
      " |-- surcharge: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- Tip_Amt: double (nullable = true)\n",
      " |-- Tolls_Amt: double (nullable = true)\n",
      " |-- Total_Amt: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check schema of data\n",
    "ny_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking a subset of our dataset\n",
    "\n",
    "ny_df_subset=ny_df.limit(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking new row count\n",
    "ny_df_subset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+---------+-----------------+------------------+---------+------------+-----------------+---------+-------+-------+---------+---------+\n",
      "|vendor_name|Trip_Pickup_DateTime|Trip_Dropoff_DateTime|Passenger_Count|     Trip_Distance|         Start_Lon|Start_Lat|Rate_Code|store_and_forward|           End_Lon|  End_Lat|Payment_Type|         Fare_Amt|surcharge|mta_tax|Tip_Amt|Tolls_Amt|Total_Amt|\n",
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+---------+-----------------+------------------+---------+------------+-----------------+---------+-------+-------+---------+---------+\n",
      "|        VTS| 2009-01-04 02:52:00|  2009-01-04 03:02:00|              1|              2.63|        -73.991957|40.721567|     NULL|             NULL|        -73.993803|40.695922|        CASH|              8.9|      0.5|   NULL|    0.0|      0.0|      9.4|\n",
      "|        VTS| 2009-01-04 03:31:00|  2009-01-04 03:38:00|              3|              4.55|        -73.982102| 40.73629|     NULL|             NULL|         -73.95585| 40.76803|      Credit|             12.1|      0.5|   NULL|    2.0|      0.0|     14.6|\n",
      "|        VTS| 2009-01-03 15:43:00|  2009-01-03 15:57:00|              5|             10.35|        -74.002587|40.739748|     NULL|             NULL|        -73.869983|40.770225|      Credit|             23.7|      0.0|   NULL|   4.74|      0.0|    28.44|\n",
      "|        DDS| 2009-01-01 20:52:58|  2009-01-01 21:14:00|              1|               5.0|        -73.974267|40.790955|     NULL|             NULL|-73.99655799999998|40.731849|      CREDIT|             14.9|      0.5|   NULL|   3.05|      0.0|    18.45|\n",
      "|        DDS| 2009-01-24 16:18:23|  2009-01-24 16:24:56|              1|               0.4|         -74.00158|40.719382|     NULL|             NULL|-74.00837799999998| 40.72035|        CASH|              3.7|      0.0|   NULL|    0.0|      0.0|      3.7|\n",
      "|        DDS| 2009-01-16 22:35:59|  2009-01-16 22:43:35|              2|               1.2|        -73.989806|40.735006|     NULL|             NULL|        -73.985021|40.724494|        CASH|              6.1|      0.5|   NULL|    0.0|      0.0|      6.6|\n",
      "|        DDS| 2009-01-21 08:55:57|  2009-01-21 09:05:42|              1|               0.4|-73.98404999999998|40.743544|     NULL|             NULL|         -73.98026|40.748926|      CREDIT|              5.7|      0.0|   NULL|    1.0|      0.0|      6.7|\n",
      "|        VTS| 2009-01-04 04:31:00|  2009-01-04 04:36:00|              1|              1.72|        -73.992635|40.748362|     NULL|             NULL|        -73.995585|40.728307|        CASH|              6.1|      0.5|   NULL|    0.0|      0.0|      6.6|\n",
      "|        CMT| 2009-01-05 16:29:02|  2009-01-05 16:40:21|              1|               1.6|         -73.96969|40.749244|     NULL|             NULL|        -73.990413|40.751082|      Credit|8.699999999999998|      0.0|   NULL|    1.3|      0.0|     10.0|\n",
      "|        CMT| 2009-01-05 18:53:13|  2009-01-05 18:57:45|              1|0.6999999999999998|        -73.955173|40.783044|     NULL|             NULL|-73.95859799999998|40.774822|        Cash|              5.9|      0.0|   NULL|    0.0|      0.0|      5.9|\n",
      "|        CMT| 2009-01-05 08:15:38|  2009-01-05 08:16:44|              1|0.2999999999999999|        -73.986824|40.750893|     NULL|             NULL|-73.98411799999998|40.751437|        Cash|              2.9|      0.0|   NULL|    0.0|      0.0|      2.9|\n",
      "|        CMT| 2009-01-05 06:21:43|  2009-01-05 06:28:41|              1|               2.3|          -74.0061|40.748432|     NULL|             NULL|        -73.978437|40.762481|        Cash|              7.7|      0.0|   NULL|    0.0|      0.0|      7.7|\n",
      "|        DDS| 2009-01-20 13:44:02|  2009-01-20 13:52:43|              2|               2.1|        -73.983339|40.744782|     NULL|             NULL|         -73.98116|40.720835|        CASH|              7.3|      0.0|   NULL|    0.0|      0.0|      7.3|\n",
      "|        CMT| 2009-01-05 16:19:53|  2009-01-05 16:26:48|              2|               1.2|         -73.97351| 40.76028|     NULL|             NULL|        -73.962933|40.775119|        Cash|              6.7|      0.0|   NULL|    0.0|      0.0|      6.7|\n",
      "|        CMT| 2009-01-05 17:22:16|  2009-01-05 17:27:25|              1|               0.8|        -73.984426| 40.75748|     NULL|             NULL|-73.98251899999998|40.767165|        Cash|              5.9|      0.0|   NULL|    0.0|      0.0|      5.9|\n",
      "|        CMT| 2009-01-05 16:02:52|  2009-01-05 16:18:43|              1|               4.5|-73.99106399999998|40.727654|     NULL|             NULL|-73.94577099999998| 40.77765|        Cash|             13.9|      0.0|   NULL|    0.0|      0.0|     13.9|\n",
      "|        CMT| 2009-01-05 12:15:06|  2009-01-05 12:27:58|              1|               1.7|        -74.001678|  40.7473|     NULL|             NULL|-73.97895699999998|40.750394|        Cash|              8.5|      0.0|   NULL|    0.0|      0.0|      8.5|\n",
      "|        CMT| 2009-01-05 07:49:57|  2009-01-05 07:54:11|              1|               1.0|-73.98245699999998|40.731475|     NULL|             NULL|        -73.973011|40.743387|      Credit|              4.5|      0.0|   NULL|    1.0|      0.0|      5.5|\n",
      "|        DDS| 2009-01-23 23:57:34|  2009-01-24 00:12:40|              2|               5.0|        -73.992554|40.724476|     NULL|             NULL|-73.95306499999998|40.777555|      CREDIT|             13.3|      0.5|   NULL|   3.45|      0.0|    17.25|\n",
      "|        CMT| 2009-01-05 10:23:13|  2009-01-05 10:33:56|              1|               1.3|        -73.990089|40.759027|     NULL|             NULL|        -73.983974|40.746938|        Cash|              7.3|      0.0|   NULL|    0.0|      0.0|      7.3|\n",
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+---------+-----------------+------------------+---------+------------+-----------------+---------+-------+-------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_df_subset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------------+---------------+-------------+---------+---------+---------+-----------------+-------+-------+------------+--------+---------+-------+-------+---------+---------+-----+\n",
      "|vendor_name|Trip_Pickup_DateTime|Trip_Dropoff_DateTime|Passenger_Count|Trip_Distance|Start_Lon|Start_Lat|Rate_Code|store_and_forward|End_Lon|End_Lat|Payment_Type|Fare_Amt|surcharge|mta_tax|Tip_Amt|Tolls_Amt|Total_Amt|count|\n",
      "+-----------+--------------------+---------------------+---------------+-------------+---------+---------+---------+-----------------+-------+-------+------------+--------+---------+-------+-------+---------+---------+-----+\n",
      "+-----------+--------------------+---------------------+---------------+-------------+---------+---------+---------+-----------------+-------+-------+------------+--------+---------+-------+-------+---------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checkinf for duplicate rows\n",
    "ny_df_subset.groupBy('vendor_name',\n",
    " 'Trip_Pickup_DateTime',\n",
    " 'Trip_Dropoff_DateTime',\n",
    " 'Passenger_Count',\n",
    " 'Trip_Distance',\n",
    " 'Start_Lon',\n",
    " 'Start_Lat',\n",
    " 'Rate_Code',\n",
    " 'store_and_forward',\n",
    " 'End_Lon',\n",
    " 'End_Lat',\n",
    " 'Payment_Type',\n",
    " 'Fare_Amt',\n",
    " 'surcharge',\n",
    " 'mta_tax',\n",
    " 'Tip_Amt',\n",
    " 'Tolls_Amt',\n",
    " 'Total_Amt').count().filter('count > 1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vendor_name 0\n",
      "Trip_Pickup_DateTime 0\n",
      "Trip_Dropoff_DateTime 0\n",
      "Passenger_Count 0\n",
      "Trip_Distance 0\n",
      "Start_Lon 0\n",
      "Start_Lat 0\n",
      "Rate_Code 20000\n",
      "store_and_forward 20000\n",
      "End_Lon 0\n",
      "End_Lat 0\n",
      "Payment_Type 0\n",
      "Fare_Amt 0\n",
      "surcharge 0\n",
      "mta_tax 20000\n",
      "Tip_Amt 0\n",
      "Tolls_Amt 0\n",
      "Total_Amt 0\n"
     ]
    }
   ],
   "source": [
    "#Find the missing values in the dataset\n",
    "for column in ny_df_subset.columns:\n",
    "  null_count= ny_df_subset.filter(f.col(column).isNull()).count()\n",
    "  print(column, null_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vendor_name', 0),\n",
       " ('Trip_Pickup_DateTime', 0),\n",
       " ('Trip_Dropoff_DateTime', 0),\n",
       " ('Passenger_Count', 0),\n",
       " ('Trip_Distance', 0),\n",
       " ('Start_Lon', 0),\n",
       " ('Start_Lat', 0),\n",
       " ('Rate_Code', 20000),\n",
       " ('store_and_forward', 20000),\n",
       " ('End_Lon', 0),\n",
       " ('End_Lat', 0),\n",
       " ('Payment_Type', 0),\n",
       " ('Fare_Amt', 0),\n",
       " ('surcharge', 0),\n",
       " ('mta_tax', 20000),\n",
       " ('Tip_Amt', 0),\n",
       " ('Tolls_Amt', 0),\n",
       " ('Total_Amt', 0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FInding minssing values using list comprehension\n",
    "null_counts_2= [(column, ny_df_subset.where(f.col(column).isNull()).count()) for column in ny_df_subset.columns]\n",
    "null_counts_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rate_Code', 'store_and_forward', 'mta_tax']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting columns to drop\n",
    "columns_to_drop = [column for column, count in null_counts_2 if count > 0.1 * ny_df_subset.count()]\n",
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vendor_name',\n",
       " 'Trip_Pickup_DateTime',\n",
       " 'Trip_Dropoff_DateTime',\n",
       " 'Passenger_Count',\n",
       " 'Trip_Distance',\n",
       " 'Start_Lon',\n",
       " 'Start_Lat',\n",
       " 'End_Lon',\n",
       " 'End_Lat',\n",
       " 'Payment_Type',\n",
       " 'Fare_Amt',\n",
       " 'surcharge',\n",
       " 'Tip_Amt',\n",
       " 'Tolls_Amt',\n",
       " 'Total_Amt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Droping columns with more than 10% nulls\n",
    "ny_df_subset= ny_df_subset.drop(*columns_to_drop)\n",
    "\n",
    "ny_df_subset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+------------------+---------+------------+-----------------+---------+-------+---------+---------+\n",
      "|vendor_name|Trip_Pickup_DateTime|Trip_Dropoff_DateTime|Passenger_Count|     Trip_Distance|         Start_Lon|Start_Lat|           End_Lon|  End_Lat|Payment_Type|         Fare_Amt|surcharge|Tip_Amt|Tolls_Amt|Total_Amt|\n",
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+------------------+---------+------------+-----------------+---------+-------+---------+---------+\n",
      "|        VTS| 2009-01-04 02:52:00|  2009-01-04 03:02:00|              1|              2.63|        -73.991957|40.721567|        -73.993803|40.695922|        CASH|              8.9|      0.5|    0.0|      0.0|      9.4|\n",
      "|        VTS| 2009-01-04 03:31:00|  2009-01-04 03:38:00|              3|              4.55|        -73.982102| 40.73629|         -73.95585| 40.76803|      Credit|             12.1|      0.5|    2.0|      0.0|     14.6|\n",
      "|        VTS| 2009-01-03 15:43:00|  2009-01-03 15:57:00|              5|             10.35|        -74.002587|40.739748|        -73.869983|40.770225|      Credit|             23.7|      0.0|   4.74|      0.0|    28.44|\n",
      "|        DDS| 2009-01-01 20:52:58|  2009-01-01 21:14:00|              1|               5.0|        -73.974267|40.790955|-73.99655799999998|40.731849|      CREDIT|             14.9|      0.5|   3.05|      0.0|    18.45|\n",
      "|        DDS| 2009-01-24 16:18:23|  2009-01-24 16:24:56|              1|               0.4|         -74.00158|40.719382|-74.00837799999998| 40.72035|        CASH|              3.7|      0.0|    0.0|      0.0|      3.7|\n",
      "|        DDS| 2009-01-16 22:35:59|  2009-01-16 22:43:35|              2|               1.2|        -73.989806|40.735006|        -73.985021|40.724494|        CASH|              6.1|      0.5|    0.0|      0.0|      6.6|\n",
      "|        DDS| 2009-01-21 08:55:57|  2009-01-21 09:05:42|              1|               0.4|-73.98404999999998|40.743544|         -73.98026|40.748926|      CREDIT|              5.7|      0.0|    1.0|      0.0|      6.7|\n",
      "|        VTS| 2009-01-04 04:31:00|  2009-01-04 04:36:00|              1|              1.72|        -73.992635|40.748362|        -73.995585|40.728307|        CASH|              6.1|      0.5|    0.0|      0.0|      6.6|\n",
      "|        CMT| 2009-01-05 16:29:02|  2009-01-05 16:40:21|              1|               1.6|         -73.96969|40.749244|        -73.990413|40.751082|      Credit|8.699999999999998|      0.0|    1.3|      0.0|     10.0|\n",
      "|        CMT| 2009-01-05 18:53:13|  2009-01-05 18:57:45|              1|0.6999999999999998|        -73.955173|40.783044|-73.95859799999998|40.774822|        Cash|              5.9|      0.0|    0.0|      0.0|      5.9|\n",
      "|        CMT| 2009-01-05 08:15:38|  2009-01-05 08:16:44|              1|0.2999999999999999|        -73.986824|40.750893|-73.98411799999998|40.751437|        Cash|              2.9|      0.0|    0.0|      0.0|      2.9|\n",
      "|        CMT| 2009-01-05 06:21:43|  2009-01-05 06:28:41|              1|               2.3|          -74.0061|40.748432|        -73.978437|40.762481|        Cash|              7.7|      0.0|    0.0|      0.0|      7.7|\n",
      "|        DDS| 2009-01-20 13:44:02|  2009-01-20 13:52:43|              2|               2.1|        -73.983339|40.744782|         -73.98116|40.720835|        CASH|              7.3|      0.0|    0.0|      0.0|      7.3|\n",
      "|        CMT| 2009-01-05 16:19:53|  2009-01-05 16:26:48|              2|               1.2|         -73.97351| 40.76028|        -73.962933|40.775119|        Cash|              6.7|      0.0|    0.0|      0.0|      6.7|\n",
      "|        CMT| 2009-01-05 17:22:16|  2009-01-05 17:27:25|              1|               0.8|        -73.984426| 40.75748|-73.98251899999998|40.767165|        Cash|              5.9|      0.0|    0.0|      0.0|      5.9|\n",
      "|        CMT| 2009-01-05 16:02:52|  2009-01-05 16:18:43|              1|               4.5|-73.99106399999998|40.727654|-73.94577099999998| 40.77765|        Cash|             13.9|      0.0|    0.0|      0.0|     13.9|\n",
      "|        CMT| 2009-01-05 12:15:06|  2009-01-05 12:27:58|              1|               1.7|        -74.001678|  40.7473|-73.97895699999998|40.750394|        Cash|              8.5|      0.0|    0.0|      0.0|      8.5|\n",
      "|        CMT| 2009-01-05 07:49:57|  2009-01-05 07:54:11|              1|               1.0|-73.98245699999998|40.731475|        -73.973011|40.743387|      Credit|              4.5|      0.0|    1.0|      0.0|      5.5|\n",
      "|        DDS| 2009-01-23 23:57:34|  2009-01-24 00:12:40|              2|               5.0|        -73.992554|40.724476|-73.95306499999998|40.777555|      CREDIT|             13.3|      0.5|   3.45|      0.0|    17.25|\n",
      "|        CMT| 2009-01-05 10:23:13|  2009-01-05 10:33:56|              1|               1.3|        -73.990089|40.759027|        -73.983974|40.746938|        Cash|              7.3|      0.0|    0.0|      0.0|      7.3|\n",
      "+-----------+--------------------+---------------------+---------------+------------------+------------------+---------+------------------+---------+------------+-----------------+---------+-------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_df_subset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data transformation\n",
    "\n",
    "ny_df_subset=ny_df_subset.filter(\n",
    "    (f.col('Passenger_Count') > 0.0) &\n",
    "    (f.col('Trip_Distance') > 0.0) & \n",
    "    (f.col(\"Fare_Amt\") > 0.0) &\n",
    "    (f.col(\"Total_Amt\") > 0.0) & \n",
    "    (f.col(\"Tip_Amt\")>= 0.0) &\n",
    "    (f.col(\"Tolls_Amt\")>= 0.0) &\n",
    "    (f.col(\"surcharge\") >= 0.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_df_subset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vendor_name', 'string'),\n",
       " ('Trip_Pickup_DateTime', 'string'),\n",
       " ('Trip_Dropoff_DateTime', 'string'),\n",
       " ('Passenger_Count', 'bigint'),\n",
       " ('Trip_Distance', 'double'),\n",
       " ('Start_Lon', 'double'),\n",
       " ('Start_Lat', 'double'),\n",
       " ('End_Lon', 'double'),\n",
       " ('End_Lat', 'double'),\n",
       " ('Payment_Type', 'string'),\n",
       " ('Fare_Amt', 'double'),\n",
       " ('surcharge', 'double'),\n",
       " ('Tip_Amt', 'double'),\n",
       " ('Tolls_Amt', 'double'),\n",
       " ('Total_Amt', 'double')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking data type\n",
    "ny_df_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing data types\n",
    "columns_to_cast = {\n",
    "    \"Trip_Pickup_DateTime\": \"timestamp\",\n",
    "    \"Trip_Dropoff_DateTime\": \"timestamp\",\n",
    "    \"Passenger_Count\": \"integer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing data types\n",
    "for col_name, col_type in columns_to_cast.items():\n",
    "    ny_df_subset= ny_df_subset.withColumn(col_name, f.col(col_name).cast(col_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vendor_name', 'string'),\n",
       " ('Trip_Pickup_DateTime', 'timestamp'),\n",
       " ('Trip_Dropoff_DateTime', 'timestamp'),\n",
       " ('Passenger_Count', 'int'),\n",
       " ('Trip_Distance', 'double'),\n",
       " ('Start_Lon', 'double'),\n",
       " ('Start_Lat', 'double'),\n",
       " ('End_Lon', 'double'),\n",
       " ('End_Lat', 'double'),\n",
       " ('Payment_Type', 'string'),\n",
       " ('Fare_Amt', 'double'),\n",
       " ('surcharge', 'double'),\n",
       " ('Tip_Amt', 'double'),\n",
       " ('Tolls_Amt', 'double'),\n",
       " ('Total_Amt', 'double')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_df_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vendor_name', 'Payment_Type']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out all categorical columns\n",
    "categorical_columns= [item[0] for item in ny_df_subset.dtypes if item[1].startswith('string')]\n",
    "\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|vendor_name|\n",
      "+-----------+\n",
      "|        VTS|\n",
      "|        DDS|\n",
      "|        CMT|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the distinct values in the categorical data\n",
    "ny_df_subset.select('vendor_name').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Payment_Type|\n",
      "+------------+\n",
      "|        CASH|\n",
      "|      Credit|\n",
      "|      CREDIT|\n",
      "|        Cash|\n",
      "|   No Charge|\n",
      "|     Dispute|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the distinct values in the categorical data\n",
    "ny_df_subset.select('Payment_Type').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing payment_type column\n",
    "ny_df_subset= ny_df_subset.withColumn(\"Payment_Type\", \n",
    "                                      when(f.col('Payment_Type')== 'CASH', 'Cash')\n",
    "                                      .when(f.col('Payment_Type') == 'CREDIT', 'Credit')\n",
    "                                      .otherwise(f.col('Payment_Type'))\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Payment_Type|\n",
      "+------------+\n",
      "|        Cash|\n",
      "|      Credit|\n",
      "|   No Charge|\n",
      "|     Dispute|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ny_df_subset.select('Payment_Type').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Different Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|vendor_id|vendor_name|\n",
      "+---------+-----------+\n",
      "|        1|        VTS|\n",
      "|        2|        VTS|\n",
      "|        3|        VTS|\n",
      "|        4|        DDS|\n",
      "|        5|        DDS|\n",
      "|        6|        DDS|\n",
      "|        7|        DDS|\n",
      "|        8|        VTS|\n",
      "|        9|        CMT|\n",
      "|       10|        CMT|\n",
      "|       11|        CMT|\n",
      "|       12|        CMT|\n",
      "|       13|        DDS|\n",
      "|       14|        CMT|\n",
      "|       15|        CMT|\n",
      "|       16|        CMT|\n",
      "|       17|        CMT|\n",
      "|       18|        CMT|\n",
      "|       19|        DDS|\n",
      "|       20|        CMT|\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating vendor table\n",
    "\n",
    "vendors= ny_df_subset.select('vendor_name') \\\n",
    "                    .withColumn('vendor_id', monotonically_increasing_id()+1) \\\n",
    "                    .select('vendor_id', 'vendor_name')\n",
    "\n",
    "vendors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendors.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------+---------+-------+---------+---------+\n",
      "|payment_id|Payment_Type|Fare_Amt|surcharge|Tip_Amt|Tolls_Amt|Total_Amt|\n",
      "+----------+------------+--------+---------+-------+---------+---------+\n",
      "|         1|        Cash|     8.9|      0.5|    0.0|      0.0|      9.4|\n",
      "|         2|      Credit|    12.1|      0.5|    2.0|      0.0|     14.6|\n",
      "|         3|      Credit|    23.7|      0.0|   4.74|      0.0|    28.44|\n",
      "|         4|      Credit|    14.9|      0.5|   3.05|      0.0|    18.45|\n",
      "|         5|        Cash|     3.7|      0.0|    0.0|      0.0|      3.7|\n",
      "+----------+------------+--------+---------+-------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payments= ny_df_subset.select('Payment_Type', 'Fare_Amt', 'surcharge', 'Tip_Amt', 'Tolls_Amt', 'Total_Amt') \\\n",
    "                      .withColumn('payment_id', monotonically_increasing_id()+1) \\\n",
    "                      .select('payment_id','Payment_Type', 'Fare_Amt', 'surcharge', 'Tip_Amt', 'Tolls_Amt', 'Total_Amt' )\n",
    "\n",
    "payments.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+----------+---------+\n",
      "|location_id| Start_Lon|Start_Lat|   End_Lon|  End_Lat|\n",
      "+-----------+----------+---------+----------+---------+\n",
      "|          1|-73.991957|40.721567|-73.993803|40.695922|\n",
      "|          2|-73.982102| 40.73629| -73.95585| 40.76803|\n",
      "|          3|-74.002587|40.739748|-73.869983|40.770225|\n",
      "+-----------+----------+---------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Locations table\n",
    "\n",
    "locations= ny_df_subset.select('Start_Lon', 'Start_Lat', 'End_Lon', 'End_Lat') \\\n",
    "                       .withColumn('location_id', monotonically_increasing_id()+1) \\\n",
    "                       .select('location_id','Start_Lon', 'Start_Lat', 'End_Lon', 'End_Lat')\n",
    "\n",
    "locations.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------------------+---------------+------------------+---------+----------+-----------+\n",
      "|trip_id|Trip_Pickup_DateTime|Trip_Dropoff_DateTime|Passenger_Count|     Trip_Distance|vendor_id|payment_id|location_id|\n",
      "+-------+--------------------+---------------------+---------------+------------------+---------+----------+-----------+\n",
      "|      1| 2009-01-04 02:52:00|  2009-01-04 03:02:00|              1|              2.63|        1|         1|          1|\n",
      "|      2| 2009-01-04 03:31:00|  2009-01-04 03:38:00|              3|              4.55|        2|         2|          2|\n",
      "|      3| 2009-01-03 15:43:00|  2009-01-03 15:57:00|              5|             10.35|        3|         3|          3|\n",
      "|      4| 2009-01-01 20:52:58|  2009-01-01 21:14:00|              1|               5.0|        4|         4|          4|\n",
      "|      5| 2009-01-24 16:18:23|  2009-01-24 16:24:56|              1|               0.4|        5|         5|          5|\n",
      "|      6| 2009-01-16 22:35:59|  2009-01-16 22:43:35|              2|               1.2|        6|         6|          6|\n",
      "|      7| 2009-01-21 08:55:57|  2009-01-21 09:05:42|              1|               0.4|        7|         7|          7|\n",
      "|      8| 2009-01-04 04:31:00|  2009-01-04 04:36:00|              1|              1.72|        8|         8|          8|\n",
      "|      9| 2009-01-05 16:29:02|  2009-01-05 16:40:21|              1|               1.6|        9|         9|          9|\n",
      "|     10| 2009-01-05 18:53:13|  2009-01-05 18:57:45|              1|0.6999999999999998|       10|        10|         10|\n",
      "|     11| 2009-01-05 08:15:38|  2009-01-05 08:16:44|              1|0.2999999999999999|       11|        11|         11|\n",
      "|     12| 2009-01-05 06:21:43|  2009-01-05 06:28:41|              1|               2.3|       12|        12|         12|\n",
      "|     13| 2009-01-20 13:44:02|  2009-01-20 13:52:43|              2|               2.1|       13|        13|         13|\n",
      "|     14| 2009-01-05 16:19:53|  2009-01-05 16:26:48|              2|               1.2|       14|        14|         14|\n",
      "|     15| 2009-01-05 17:22:16|  2009-01-05 17:27:25|              1|               0.8|       15|        15|         15|\n",
      "|     16| 2009-01-05 16:02:52|  2009-01-05 16:18:43|              1|               4.5|       16|        16|         16|\n",
      "|     17| 2009-01-05 12:15:06|  2009-01-05 12:27:58|              1|               1.7|       17|        17|         17|\n",
      "|     18| 2009-01-05 07:49:57|  2009-01-05 07:54:11|              1|               1.0|       18|        18|         18|\n",
      "|     19| 2009-01-23 23:57:34|  2009-01-24 00:12:40|              2|               5.0|       19|        19|         19|\n",
      "|     20| 2009-01-05 10:23:13|  2009-01-05 10:33:56|              1|               1.3|       20|        20|         20|\n",
      "+-------+--------------------+---------------------+---------------+------------------+---------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Trip Table\n",
    "\n",
    "trips= ny_df_subset.withColumn('trip_id',monotonically_increasing_id()+1 )\n",
    "\n",
    "trips= trips.join(vendors, trips.trip_id==vendors.vendor_id, 'left')\\\n",
    "            .join(payments,trips.trip_id==payments.payment_id, 'left' )\\\n",
    "            .join (locations,trips.trip_id==locations.location_id, 'left' ) \\\n",
    "            .select ('trip_id','Trip_Pickup_DateTime','Trip_Dropoff_DateTime','Passenger_Count',\n",
    "                     'Trip_Distance','vendor_id','payment_id', 'location_id', )\n",
    "\n",
    "trips.show()             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an environment for password\n",
    "load_dotenv()\n",
    "\n",
    "password= os.getenv('PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cREATING CONNECTION TO DATABASE\n",
    "def get_connection():\n",
    "    connection= psy.connect(dbname='ny_taxi_trips', user='postgres', password=password, host='localhost', port=5432)\n",
    "    return connection\n",
    "\n",
    "conn=get_connection()\n",
    "cur=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tables in database\n",
    "\n",
    "conn= get_connection()\n",
    "cur=conn.cursor()\n",
    "\n",
    "create_table_query= '''\n",
    "                    DROP TABLE IF EXISTS vendors CASCADE;\n",
    "                    DROP TABLE IF EXISTS payments CASCADE;\n",
    "                    DROP TABLE IF EXISTS locations CASCADE;\n",
    "                    DROP TABLE IF EXISTS trips CASCADE;\n",
    "\n",
    "                    CREATE TABLE IF NOT EXISTS vendors (\n",
    "                        vendor_id INT PRIMARY KEY,\n",
    "                        vendor_name VARCHAR(50)\n",
    "                    );\n",
    "\n",
    "                    CREATE TABLE locations (\n",
    "                        location_id INT PRIMARY KEY,\n",
    "                        start_lon FLOAT,\n",
    "                        start_lat FLOAT,\n",
    "                        end_lon FLOAT,\n",
    "                        end_lat FLOAT\n",
    "                    );\n",
    "\n",
    "                    CREATE TABLE payments (\n",
    "                        payment_id INT PRIMARY KEY,\n",
    "                        payment_type VARCHAR(50),\n",
    "                        fare_amt FLOAT,\n",
    "                        surcharge FLOAT,\n",
    "                        tip_amt FLOAT,\n",
    "                        tolls_amt FLOAT,\n",
    "                        total_amt FLOAT\n",
    "                    );\n",
    "\n",
    "                    CREATE TABLE trips (\n",
    "                        trip_id INT PRIMARY KEY,\n",
    "                        trip_pickup_datetime TIMESTAMP,\n",
    "                        trip_dropoff_datetime TIMESTAMP,\n",
    "                        passenger_count INT,\n",
    "                        trip_distance FLOAT,\n",
    "                        vendor_id INT,\n",
    "                        payment_id INT,\n",
    "                        location_id INT,\n",
    "                        FOREIGN KEY (vendor_id) REFERENCES vendors(vendor_id),\n",
    "                        FOREIGN KEY (payment_id) REFERENCES payments(payment_id),\n",
    "                        FOREIGN KEY (location_id) REFERENCES locations(location_id)\n",
    "                       );\n",
    "\n",
    "    '''\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data Into Postgresql Database Using JDBC Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL JDBC URL and properties\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5432/ny_taxi_trips\"\n",
    "jdbc_properties = {\"user\": \"postgres\", \"password\": password, \"driver\":\"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_save = [\n",
    "    (vendors, \"vendors\"),\n",
    "    (locations, \"locations\"),\n",
    "    (payments, \"payments\"),\n",
    "    (trips, \"trips\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendors.write.jdbc(url=jdbc_url, table='vendors',mode='overwrite', properties=jdbc_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe, table_name in dataframes_to_save:\n",
    "    writer=dataframe.write \\\n",
    "    .format('jdbc') \\\n",
    "    .option ('url', jdbc_url) \\\n",
    "    .option ('dbtable', table_name) \\\n",
    "    \n",
    "    # Set each property individually\n",
    "    for key, value in jdbc_properties.items():\n",
    "        writer_incl_properties = writer.option(key, value)\n",
    "\n",
    "    writer_incl_properties.mode('append').save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data Into Postgresql Database Using SqlAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "connection_string = f'postgresql://postgres:postgres@localhost/taxi_data'\n",
    "\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.to_sql('trips', engine, if_exists='replace', index=False)\n",
    "vendors.to_sql('vendors', engine, if_exists='replace', index=False)\n",
    "payments.to_sql('payments', engine, if_exists='replace', index=False)\n",
    "locations.to_sql('locations', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert To Get Pyhton Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbconvert\n",
      "  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert)\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jinja2>=3.0 (from nbconvert)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert) (5.7.2)\n",
      "Collecting jupyterlab-pygments (from nbconvert)\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting markupsafe>=2.0 (from nbconvert)\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert)\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert)\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert)\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert) (24.0)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert)\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert) (2.18.0)\n",
      "Collecting tinycss2 (from nbconvert)\n",
      "  Downloading tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from nbconvert) (5.14.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from bleach!=5.0.0->nbconvert) (1.16.0)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core>=4.7->nbconvert) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core>=4.7->nbconvert) (306)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from nbclient>=0.5.0->nbconvert) (8.6.2)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert)\n",
      "  Downloading fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat>=5.7->nbconvert)\n",
      "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hp spectre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (23.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat>=5.7->nbconvert)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat>=5.7->nbconvert)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat>=5.7->nbconvert)\n",
      "  Downloading rpds_py-0.18.1-cp311-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\hp spectre\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.4.1)\n",
      "Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "   ---------------------------------------- 0.0/257.4 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 204.8/257.4 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 257.4/257.4 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 162.8/162.8 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.3/133.3 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/48.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.0/48.0 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.9/147.9 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Downloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 88.3/88.3 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.1-cp311-none-win_amd64.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 209.0/209.0 kB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: webencodings, fastjsonschema, tinycss2, soupsieve, rpds-py, pandocfilters, mistune, markupsafe, jupyterlab-pygments, defusedxml, bleach, referencing, jinja2, beautifulsoup4, jsonschema-specifications, jsonschema, nbformat, nbclient, nbconvert\n",
      "Successfully installed beautifulsoup4-4.12.3 bleach-6.1.0 defusedxml-0.7.1 fastjsonschema-2.19.1 jinja2-3.1.4 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 jupyterlab-pygments-0.3.0 markupsafe-2.1.5 mistune-3.0.2 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 pandocfilters-1.5.1 referencing-0.35.1 rpds-py-0.18.1 soupsieve-2.5 tinycss2-1.3.0 webencodings-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ny_data.ipynb to script\n",
      "[NbConvertApp] Writing 5502 bytes to ny_data.py\n"
     ]
    }
   ],
   "source": [
    "# Getting python script\n",
    "!pip install nbconvert\n",
    "\n",
    "!jupyter nbconvert --to script ny_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
